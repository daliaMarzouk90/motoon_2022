{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "     ---------------------------------------- 35.6/35.6 MB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\dalia marzouk\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from opencv-python) (1.22.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images Data Augmentation\n",
    "## opencv important functions\n",
    "<b>get image size: </b>dimensions = img.shape </br>\n",
    "<b>image resizing: </b>new_img = cv2.resize(img, dim(new_width, new_height))</br>\n",
    "<b>transfer to grayscale</b>gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</br>\n",
    "\n",
    "## Examples for Data Augmentation\n",
    "### Affine transformation\n",
    "In geometry transformation is applied by a transofrmation matrix\n",
    "<ul>\n",
    "<li>For translation this matrix is used</li>\n",
    "<img src=\"images/5_translation.png\"></img>\n",
    "<li>For rotation this matrix is used</li>\n",
    "<img src=\"images/6_rotation.png\"></img>\n",
    "</ul>\n",
    "<b>opencv automates this process on the following two steps</b>\n",
    "<ol>\n",
    "<li>\n",
    "<b>Get transformation matrix</b>\n",
    "<ul>\n",
    "<li><b>For translation:</b> M = np.float32([[1,0,vertical_shift],[0,1,horizontal_shift]])</li>\n",
    "<li><b>For rotation:</b> M = cv::getRotationMatrix2D(center, rotation_angle, scale)</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>\n",
    "<b>apply transformation matrix on the image</b></br>\n",
    "transformed_img = cv2.warpAffine(img,M,(width,height))\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "### Image flipping\n",
    "flip_type = 0 #0: vertical, 1: horizontal, -1: bot vertical and horizontal\n",
    "flipped_img = cv2.flip(img, 0)\n",
    "\n",
    "### Adding Random Exposure (In case that the model should tolerate all lighting conditions)\n",
    "edit brightness and contrast\n",
    "transformed_img = cv2.convertScaleAbs(img, alph, beta)\n",
    "<ul> <li>alpha = 1.5 # Contrast control (1.0-3.0)</li>\n",
    "<li>beta = 0 # Brightness control (0-100)</li></ul>\n",
    "\n",
    "### Normalizing channels\n",
    "<ul>\n",
    "<li>Transform the color range from [0, 255] to [0, 1]</li>\n",
    "<li>Subtract the mean value of each channel</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## opencv transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "img = cv2.imread('bird.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create data augmentation function that exsposes 10 random examples of the input image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring data in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: https://github.com/random-forests/tensorflow-workshop/blob/master/archive/examples/07_structured_data.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "census_train = pd.read_csv('./data/census/train.csv', index_col=False) \n",
    "census_test = pd.read_csv('./data/census/test.csv', skiprows=1, index_col=False) \n",
    "\n",
    "\n",
    "census_train = census_train.dropna(how=\"any\", axis=0)\n",
    "census_test = census_test.dropna(how=\"any\", axis=0)\n",
    "\n",
    "#you turn! Analyise data\n",
    "# get hash unique values\n",
    "# get age unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of the feature columns we'll use to train the Linear model\n",
    "feature_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.feature_column.feature_column_v2.BucketizedColumn"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1- Numerical attributes\n",
    "##1.1- Bucketizing\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.feature_column.bucketized_column\n",
    "\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "age_buckets_1 = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column('age'), \n",
    "    boundaries=[31, 46, 60, 75, 90] # specify the ranges\n",
    ")\n",
    "\n",
    "age_buckets_2 = tf.feature_column.bucketized_column(\n",
    "    tf.feature_column.numeric_column('age'),\n",
    "    list(range(10))\n",
    ")\n",
    "\n",
    "feature_columns.append(age_buckets_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0, 1, 2]\n",
    "depth = 3\n",
    "tf.one_hot(indices, depth)  # output: [3 x 3]\n",
    "# [[1., 0., 0.],\n",
    "#  [0., 1., 0.],\n",
    "#  [0., 0., 1.]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2\n",
    "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"education\", [\n",
    "        \"Bachelors\", \"HS-grad\", \"11th\", \"Masters\", \"9th\",\n",
    "        \"Some-college\", \"Assoc-acdm\", \"Assoc-voc\", \"7th-8th\",\n",
    "        \"Doctorate\", \"Prof-school\", \"5th-6th\", \"10th\", \"1st-4th\",\n",
    "        \"Preschool\", \"12th\"\n",
    "    ])\n",
    "\n",
    "feature_columns.append(education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 hashed bucket\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native-country', 1000)\n",
    "feature_columns.append(native_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.4 cross column; combine two features\n",
    "age_cross_education = tf.feature_column.crossed_column(\n",
    "    [age_buckets_1, education],\n",
    "    hash_bucket_size=int(1e4) # Using a hash is handy here\n",
    ")\n",
    "feature_columns.append(age_cross_education)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d649404ee286c9341d586c87dba08392d8b7db27d1214df02d5d59f9ee48e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
