{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning System Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Evaluation Metrics\n",
    "\n",
    "### Basic Terminology\n",
    "- <b>True Positive (TP): </b> the positive examples in the test set that were classified <u>correctly</u> as positive examples\n",
    "- <b>False positive (FP): </b> the negative examples in the test set that were classified <u>wrongly</u> as positive examples\n",
    "- <b>True Negative (TN): </b> the negative examples in the test set that were classified <u>correctly</u> as negative exmples\n",
    "- <b>False Negative (FN): </b> the positive examples in the test set that wew classified <u>wrongly</u> as negative exmples</br></br>\n",
    "\n",
    "In binary classification those three categories constructs what is known as the confusion matrix</br></br>\n",
    "<center><img src=\"images/confusionMatrix.jpg\" width=300></img></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2160x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hmac import digest\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(30, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Training: %i\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = digits.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=0)\n",
    "\n",
    "predictor = SVC(gamma=0.001).fit(X_train, y_train)\n",
    "y_pred = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402   1]\n",
      " [  3  44]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Evaluate a model we should keep in mind we do not only want to get good predictions but there is a bussiness demand we should fit.\n",
    "\n",
    "#### Examples\n",
    "- <b>In breast cancer example: </b> it is important to avoid false negative more than any thing\n",
    "- <b>In autonoumus driving problem: </b> it is important to avoid accidants. If we are using obesticals detection algorithm it is important to aboid false negative\n",
    "- <b>In robot lifitng problem: </b> it is important to avoid false positive\n",
    "\n",
    "### Evaluation Metrics\n",
    "#### Accuracy\n",
    "Simply it is the sum of correctly classified examples over all test samples\n",
    "\n",
    "$Accuracy = \\frac{TP + TN}{TP + FN + TN + FP}$\n",
    "\n",
    "##### Advantages\n",
    "- Accuracy's logic is straight forward\n",
    "- It is enough if you have balanced data\n",
    "- It is enough if all what you need is to obtain how many example was classified successfully\n",
    "\n",
    "##### Disadvantage\n",
    "- Fails in giving a good idea about system behavior when the data is unbalanced\n",
    "- Do not give an accurate view regarding each class. IT gives generalized idea\n",
    "- The effect of the majority class dominates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predictor score is: {:.2f}\".format(predictor.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percision\n",
    "Measures how many of the samples predicted as positive are actually positive\n",
    "\n",
    "\n",
    "$Percision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "- Used as evaluation metric when the goal is to limit false positive.\n",
    "- For example when the goal is to test if a new drug is effective in in treating a disease in clinical trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "Measures how many of the positive samples are captured by the poisitve prediction\n",
    "\n",
    "\n",
    "$Recall = \\frac{TP}{TP + FN}$\n",
    "\n",
    "- Used as evaluation metric when the goal is to limit false negative.\n",
    "- For example in the breast cancer data set it is important to avoid false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "- you can reach good recall if you predicted all examples as positive examples. There will not be fals negatives\n",
    "- although recall and percision are very important metrics but they do not give the full picture about model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-Score\n",
    "F-score is the harmonic mean of percision and recall</br></br>\n",
    "$F = \\frac{2}{\\frac{1}{Percision} + \\frac{1}{Recall}}$</br></br>\n",
    "$F = 2 * \\frac{Percision * Recall}{Percision + Recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      1.00       403\n",
      "        True       0.98      0.94      0.96        47\n",
      "\n",
      "    accuracy                           0.99       450\n",
      "   macro avg       0.99      0.97      0.98       450\n",
      "weighted avg       0.99      0.99      0.99       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>macro avg: </b> the sum of different classes percision or recall divided by the number of classes\n",
    "<b>weighted avg: </b> the sum of weighted  classes percision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Evaluation Metrics\n",
    "### Mean Square Error\n",
    "$MSE = \\frac{1}{n} \\sum_{i=1}^{n}{(Y_i - \\^Y_i)^2}$\n",
    "\n",
    "### Absolute Mean Error\n",
    "$Absolute Error = \\frac{1}{n} \\sum_{i=1}^{n}{|Y_i - \\^Y_i|}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "\n",
    "- <b>Model Fiting or training: </b> the process of choosing the parameters of the model like the weights of the regression equation\n",
    "- <b>Model Selection: </b> the process of choosing model hyper parameters like gama in svm\n",
    "- <b>Model Evaluation: </b> the process of measuring ther performance of the model\n",
    "\n",
    "#### Train-Test-Validation Data\n",
    "- <b>Train Data: </b>The training dataset is used to fit the different models. Some times called development data\n",
    "- <b>Validation Data: </b>the validation dataset is then used for the model selection\n",
    "- <b>Test Data: </b>used to evaluate the model and predict its performance\n",
    "  - The advantage of having a test dataset that the model hasn’t seen before during the training and model selection steps is that we can obtain a less biased estimate of its ability to generalize to new data\n",
    "  \n",
    "<center><img src=\"images/modelSelection.png\" width=450><br><a href=\"https://medium.com/analytics-vidhya/cross-validation-techniques-a925782517e8\">img ref</a><br></center>\n",
    "\n",
    "#### Splitting Methods\n",
    "##### Hold-out Validation\n",
    "- Hold-out is when you split up your dataset into a 'train' and 'test' set\n",
    "- The training set is what the model is trained on\n",
    "- The test set is used to see how well that model performs on unseen data\n",
    "\n",
    "##### K-fold Cross Validation\n",
    "1. Shuffle the dataset randomly<br>\n",
    "2. Split the dataset into k groups<br>\n",
    "3. For each unique group:<br>\n",
    "  3.1 Take the group as a hold out or test data set<br>\n",
    "  3.2 Take the remaining groups as a training data set<br>\n",
    "  3.3 Fit a model on the training set and evaluate it on the test set<br>\n",
    "4. Summarize the skill of the model using the sample of model evaluation scores<br>\n",
    "\n",
    "- The advantage of having a test dataset that the model hasn’t seen before during the training and model selection steps is that we can obtain a less biased estimate of its ability to generalize to new data.\n",
    "\n",
    "<center><img src=\"images/kFoldCrossValidation.png\"></img><br><a href=\"https://medium.com/analytics-vidhya/cross-validation-techniques-a925782517e8\">image ref</a></center>\n",
    "\n",
    "\n",
    "##### Grid Search (Tuning Hyperparameters)\n",
    "<b>hyperparameter</b> is a characteristic of a model that is external to the model and whose value cannot be estimated from data</br></br>\n",
    "- By default, accuracy is the score that is optimized, but other scores can be specified in the score argument of the GridSearchCV constructor.\n",
    "- The GridSearchCV process will then construct and evaluate one model for each combination of parameters. And we select the combination that maximizes the system performance\n",
    "\n",
    "<center><img src=\"images/gridSearch.png\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> During Deep learning training process there are three terms we should be aware about:\n",
    "- Epoch: Represents one iteration over the entire dataset (everything put into the training model).\n",
    "- Batch: Refers to when we cannot pass the entire dataset into the neural network at once, so we divide the dataset into several batches.\n",
    "- Iteration: if we have 10,000 images as data and a batch size of 200. then an epoch should run 50 iterations (10,000 divided by 50)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply with skitlearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "180d529be9b1f03edfbede09fd65ea6b62ba91a89fc74d7b4af9f91428411c0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
